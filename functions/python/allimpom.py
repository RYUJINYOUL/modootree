import requests
import json
import os
import traceback
import time
import re
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
from typing import Dict, List, Tuple, Optional
from enum import Enum
from datetime import datetime, timedelta
from io import BytesIO

from google import genai
from google.genai import types
from flask import Flask, request, Response, jsonify, send_from_directory
from flask_cors import CORS
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    # âœ¨ ì¶”ê°€ëœ ë¶€ë¶„ âœ¨
    QuantizationConfig,
    ScalarQuantization,
    ScalarType,
    HnswConfig,
)

try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("âš ï¸ Pillowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# Google Cloud Storage ì§€ì›
try:
    from google.cloud import storage as gcs
    HAS_GCS = True
except ImportError:
    HAS_GCS = False
    print("âš ï¸ Google Cloud Storage ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ ìºì‹œ ì‚¬ìš©")

# ===== Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” =====
qdrant_url = os.environ.get("QDRANT_URL", "http://localhost:6333")
qdrant_api_key = os.environ.get("QDRANT_API_KEY", None)

try:
    qdrant_client = QdrantClient(
        url=qdrant_url,
        api_key=qdrant_api_key,
        prefer_grpc=True,
    )
    print(f"âœ… Qdrant ì—°ê²° ì„±ê³µ: {qdrant_url}")   # 1. qdrantì—°ê²° ì„±ê³µ
except Exception as e:
    print(f"âš ï¸ Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
    qdrant_client = None

QDRANT_COLLECTION_NAME = "search_results"
VECTOR_SIZE = 768

app = Flask(__name__)
CORS(app, resources={                                         # 2. corsì„¤ì •
    r"/*": {
        "origins": ["http://localhost:3000", "https://*"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"],
        "expose_headers": ["Content-Type"],
        "supports_credentials": False,
        "max_age": 3600
    }
})

# ===== í™˜ê²½ ë³€ìˆ˜ =====
SERPER_KEY = os.environ.get("SERPER_KEY")
NAVER_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_SECRET = os.environ.get("NAVER_CLIENT_SECRET")
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")
GCS_BUCKET_NAME = os.environ.get("GCS_BUCKET_NAME")  # ì„ íƒì‚¬í•­
USE_GCS = HAS_GCS and GCS_BUCKET_NAME is not None

gcs_client = None                                            # 3. ìºì‰¬ ì—°ê²°
if USE_GCS:
    try:
        gcs_client = gcs.Client()
        bucket = gcs_client.bucket(GCS_BUCKET_NAME)
        print(f"âœ… Google Cloud Storage ì—°ê²° ì„±ê³µ: {GCS_BUCKET_NAME}")
    except Exception as e:
        print(f"âš ï¸ GCS ì—°ê²° ì‹¤íŒ¨: {e}, ë¡œì»¬ ìºì‹œ ì‚¬ìš©")
        USE_GCS = False

client = None
if GEMINI_KEY:
    try:
        client = genai.Client(api_key=GEMINI_KEY)
    except Exception as e:
        print(f"âŒ Gemini Client ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

SEARCH_CONFIG = {
    "naver": {
        "url": "https://openapi.naver.com/v1/search/local.json",
        "headers": {
            "X-Naver-Client-Id": NAVER_ID,
            "X-Naver-Client-Secret": NAVER_SECRET,
        },
    },
    "google": {
        "url": "https://google.serper.dev/search",
        "headers": {"X-API-KEY": SERPER_KEY, "Content-Type": "application/json"},
    },
}

class SearchCategory(Enum):
    RESTAURANT = "restaurant"
    CAFE = "cafe"
    ACCOMMODATION = "accommodation"
    SHOPPING = "shopping"
    NEWS = "news"
    PRODUCT = "product"
    ACTIVITY = "activity"
    GENERAL = "general"

CATEGORY_SCHEMAS = {                                # 4. ë™ì  ìŠ¤í‚¤ë§ˆ ì„¤ì •
    SearchCategory.GENERAL: {
        "fields": [
            {"name": "name", "type": "string", "required": True},
            {"name": "category", "type": "string", "required": True},
            {"name": "summary", "type": "string", "required": True},
            {"name": "imageUrl", "type": "string", "required": False},
            {"name": "source", "type": "string", "required": True},
            {"name": "sourceURL", "type": "string", "required": True},
        ],
        "ranking": ["relevance"],
        "count": 10,
    },
    SearchCategory.RESTAURANT: {
        "fields": [
            {"name": "name", "type": "string", "required": True},
            {"name": "category", "type": "string", "required": True},
            {"name": "address", "type": "string", "required": False},
            {"name": "rating", "type": "string", "required": False},
            {"name": "price_range", "type": "string", "required": False},
            {"name": "menu", "type": "string", "required": False},
            {"name": "summary", "type": "string", "required": True},
            {"name": "imageUrl", "type": "string", "required": False},
            {"name": "source", "type": "string", "required": True},
            {"name": "sourceURL", "type": "string", "required": True},
        ],
        "ranking": ["rating", "relevance"],
        "count": 10,
    },
    SearchCategory.CAFE: {
        "fields": [
            {"name": "name", "type": "string", "required": True},
            {"name": "category", "type": "string", "required": True},
            {"name": "address", "type": "string", "required": False},
            {"name": "rating", "type": "string", "required": False},
            {"name": "menu", "type": "string", "required": False},
            {"name": "summary", "type": "string", "required": True},
            {"name": "imageUrl", "type": "string", "required": False},
            {"name": "source", "type": "string", "required": True},
            {"name": "sourceURL", "type": "string", "required": True},
        ],
        "ranking": ["rating", "relevance"],
        "count": 10,
    },
    SearchCategory.ACCOMMODATION: {
        "fields": [
            {"name": "name", "type": "string", "required": True},
            {"name": "category", "type": "string", "required": True},
            {"name": "address", "type": "string", "required": False},
            {"name": "rating", "type": "string", "required": False},
            {"name": "price_range", "type": "string", "required": True},
            {"name": "summary", "type": "string", "required": True},
            {"name": "imageUrl", "type": "string", "required": False},
            {"name": "source", "type": "string", "required": True},
            {"name": "sourceURL", "type": "string", "required": True},
        ],
        "ranking": ["rating", "price"],
        "count": 10,
    },
    SearchCategory.NEWS: {
        "fields": [
            {"name": "title", "type": "string", "required": True},
            {"name": "category", "type": "string", "required": True},
            {"name": "summary", "type": "string", "required": True},
            {"name": "published_date", "type": "string", "required": False},
            {"name": "imageUrl", "type": "string", "required": False},
            {"name": "source", "type": "string", "required": True},
            {"name": "sourceURL", "type": "string", "required": True},
        ],
        "ranking": ["recency", "relevance"],
        "count": 10,
    },
}

# ===== ì´ë¯¸ì§€ ìºì‹œ (GCS ì§€ì›) =====                                     5. ì´ë¯¸ì§€ í´ë˜ìŠ¤ ì €ì¥ ë§Œë“¬
class ImageCache:
    def __init__(self, cache_dir="./image_cache", use_gcs=False, gcs_client=None, bucket_name=None):
        self.use_gcs = use_gcs
        self.gcs_client = gcs_client
        self.bucket_name = bucket_name
        self.cache_dir = cache_dir
        
        if not self.use_gcs:
            os.makedirs(cache_dir, exist_ok=True)
    
    def get_hash(self, name: str, source_url: str = "") -> str:
        combined = f"{name}_{source_url}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def get_path(self, hash_val: str) -> str:
        return os.path.join(self.cache_dir, f"{hash_val}.jpg")
    
    def exists(self, hash_val: str) -> bool:
        if self.use_gcs:
            try:
                blob = self.gcs_client.bucket(self.bucket_name).blob(f"images/{hash_val}.jpg")
                return blob.exists()
            except Exception as e:
                print(f"âš ï¸ GCS exists í™•ì¸ ì‹¤íŒ¨: {e}")
                return False
        else:
            return os.path.exists(self.get_path(hash_val))
    
    def get_url(self, hash_val: str, full_url: bool = True) -> Optional[str]:
        if self.exists(hash_val):
            if self.use_gcs:
                # base_url = os.environ.get("BASE_URL", "https://storage.googleapis.com")
                return f"https://storage.googleapis.com/{self.bucket_name}/images/{hash_val}.jpg"
            else:
                if full_url:
                    base_url = os.environ.get("BASE_URL", "https://allimpom-run-service.run.app")
                    return f"{base_url}/images/{hash_val}.jpg"
                return f"/images/{hash_val}.jpg"
        return None
    
    def save(self, hash_val: str, image_url: str) -> Optional[str]:
        try:
            resp = requests.get(image_url, timeout=5)
            resp.raise_for_status()
            
            if HAS_PIL:
                img = Image.open(BytesIO(resp.content))
                img.thumbnail((400, 400))
                img_bytes = BytesIO()
                img.save(img_bytes, "JPEG", quality=85, optimize=True)
                image_data = img_bytes.getvalue()
            else:
                image_data = resp.content
            
            if self.use_gcs:
                blob = self.gcs_client.bucket(self.bucket_name).blob(f"images/{hash_val}.jpg")
                blob.upload_from_string(image_data, content_type="image/jpeg")
                print(f"âœ… GCSì— ì´ë¯¸ì§€ ì €ì¥: {hash_val}")
            else:
                path = self.get_path(hash_val)
                with open(path, 'wb') as f:
                    f.write(image_data)
                print(f"âœ… ë¡œì»¬ì— ì´ë¯¸ì§€ ì €ì¥: {hash_val}")
            
            return self.get_url(hash_val, full_url=True)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨ ({hash_val}): {e}")
            return None
    
    def cleanup_old_cache(self, days=30):
        """30ì¼ ì´ìƒ ëœ ìºì‹œ ì‚­ì œ"""
        try:
            cutoff = datetime.now() - timedelta(days=days)
            
            if self.use_gcs:
                bucket = self.gcs_client.bucket(self.bucket_name)
                blobs = bucket.list_blobs(prefix="images/")
                
                for blob in blobs:
                    updated_time = blob.updated
                    if updated_time and updated_time.replace(tzinfo=None) < cutoff:
                        blob.delete()
                        print(f"ğŸ—‘ï¸ GCSì—ì„œ ì‚­ì œ: {blob.name}")
            else:
                if not os.path.exists(self.cache_dir):
                    return
                
                for f in os.listdir(self.cache_dir):
                    path = os.path.join(self.cache_dir, f)
                    if os.path.isfile(path) and os.path.getmtime(path) < cutoff.timestamp():
                        os.remove(path)
                        print(f"ğŸ—‘ï¸ ë¡œì»¬ì—ì„œ ì‚­ì œ: {f}")
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

image_cache = ImageCache(use_gcs=USE_GCS, gcs_client=gcs_client, bucket_name=GCS_BUCKET_NAME)

# ===== Qdrant ê´€ë¦¬ =====
class QdrantManager:                                                            # 6. qdrant í´ë˜ìŠ¤ ë§Œë“¬
    def __init__(self, client, collection_name: str, vector_size: int):
        self.client = client
        self.collection_name = collection_name
        self.vector_size = vector_size
        self._init_collection()
    
    def _init_collection(self):
        """ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒì„±)"""

        try:
            collection = self.client.get_collection(self.collection_name)
            print(f"âœ… Qdrant ì»¬ë ‰ì…˜ ì´ë¯¸ ì¡´ì¬: {self.collection_name}")
            print(f"   - í¬ì¸íŠ¸ ìˆ˜: {collection.points_count}")
            return  

        except Exception: # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
            print(f"ğŸ“ Qdrant ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")


        try:
            print(f"  â†’ ìƒì„± ì¤‘: {self.collection_name}")
            
            # â­ í•µì‹¬: Qdrant CloudëŠ” ScalarQuantizationì„ ì§€ì›í•˜ì§€ ì•ŠìŒ
            # ê°„ë‹¨í•œ ì„¤ì •ë§Œ ì‚¬ìš©
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=self.vector_size,
                    distance=Distance.COSINE
                )
                # quantization_configì™€ hnsw_configëŠ” ì œê±°
            )
            
            print(f"âœ… Qdrant ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {self.collection_name}")
            print(f"   - ë²¡í„° í¬ê¸°: {self.vector_size}")
            print(f"   - ê±°ë¦¬ ë©”íŠ¸ë¦­: COSINE")
        
        except Exception as create_err:
            print(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {type(create_err).__name__}: {create_err}")
            raise RuntimeError(f"Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {create_err}") from create_err
    
    def store_search(self, query: str, category: str, vector: List[float],    # ê²€ìƒ‰ ê³¼ì •ì´ ëë‚œ í›„, ê·¸ ê²°ê³¼ë¥¼ ê¸°ë¡ìœ¼ë¡œ ë‚¨ê¸°ê¸° ìœ„í•œ ìš©ë„
                    recommendations: List[Dict], sources: List[Dict]):
        try:
            point_id = int(hashlib.md5(f"{query}_{datetime.now().timestamp()}".encode()).hexdigest(), 16) % (2**31)
            
            payload = {
                "query": query,
                "category": category,
                "timestamp": datetime.now().isoformat(),
                "recommendations_count": len(recommendations),
                "recommendation_names": [r.get("name", "") for r in recommendations[:5]],
                "sources_count": len(sources),
            }
            
            self.client.upsert(
                collection_name=self.collection_name,
                points=[
                    PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                ]
            )
            print(f"âœ… Qdrant ë©”íƒ€ë°ì´í„° ì €ì¥: {query} (ID: {point_id})")
        except Exception as e:
            print(f"âš ï¸ Qdrant ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def search_similar(self, query_vector: List[float], limit: int = 3) -> List[Dict]:   # qdrant ê²€ìƒ‰ ìš©ë„
        try:
            results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                score_threshold=0.75
            )
            
            similar = []
            for hit in results:
                payload = hit.payload
                similar.append({
                    "score": hit.score,
                    "query": payload.get("query"),
                    "category": payload.get("category"),
                    "recommendation_count": payload.get("recommendations_count", 0),
                })
            
            print(f"âœ… Qdrant ìœ ì‚¬ ê²€ìƒ‰: {len(similar)}ê°œ ë°œê²¬")
            return similar
        except Exception as e:
            print(f"âš ï¸ Qdrant ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

qdrant_manager = None
if qdrant_client:
    qdrant_manager = QdrantManager(qdrant_client, QDRANT_COLLECTION_NAME, VECTOR_SIZE)

def get_embedding(text: str) -> Optional[List[float]]:
    try:
        response = client.models.embed_content(
            model="text-embedding-004", # ì‚¬ìš©í•˜ë˜ ëª¨ë¸ ê·¸ëŒ€ë¡œ ìœ ì§€
            contents=text,
            config=types.EmbedContentConfig(output_dimensionality=VECTOR_SIZE)
        )
        
        # ğŸ¯ ê³µì‹ ë¬¸ì„œ ë°©ì‹ ì ìš©: .embeddings ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶”ì¶œ
        if response.embeddings and len(response.embeddings) > 0:
            # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(Embedding ê°ì²´)ì—ì„œ .valuesë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            return response.embeddings[0].values
        
        raise ValueError("Embedding list is empty.")

    except Exception as e:
        print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {type(e).__name__}: {e}")
        return None

def classify_query(query: str) -> Tuple[SearchCategory, str]:
    q = query.lower()
    keywords = {
        SearchCategory.RESTAURANT: ["ë§›ì§‘", "ìŒì‹ì ", "ë ˆìŠ¤í† ë‘", "ë¨¹ì„ê³³", "ì‹ë‹¹"],
        SearchCategory.CAFE: ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"],
        SearchCategory.ACCOMMODATION: ["ìˆ™ì†Œ", "í˜¸í…”", "ëª¨í…”", "íœì…˜", "ë¦¬ì¡°íŠ¸"],
        SearchCategory.NEWS: ["ë‰´ìŠ¤", "ê¸°ì‚¬", "ì†Œì‹"],
        SearchCategory.SHOPPING: ["ì‡¼í•‘", "êµ¬ë§¤"],
        SearchCategory.PRODUCT: ["ì œí’ˆ", "ìƒí’ˆ", "ì¶”ì²œ"],
        SearchCategory.ACTIVITY: ["ì²´í—˜", "ê´€ê´‘", "ì—¬í–‰"],
    }
    
    for category, kws in keywords.items():
        if any(kw in q for kw in kws):
            clean = query
            for word in ["ì¶”ì²œ", "ì•Œë ¤ì¤˜", "ì°¾ì•„ì¤˜", "ê²€ìƒ‰", "í•´ì¤˜"]:
                clean = clean.replace(word, "").strip()
            return category, clean
    
    return SearchCategory.GENERAL, query

def fetch_api_data(source: str, query: str) -> Dict:
    config = SEARCH_CONFIG.get(source)
    if not config:
        return {"source": source, "error": "config not found"}
    
    try:
        if source == "naver":
            r = requests.get(
                config["url"],
                headers=config["headers"],
                params={"query": query, "display": 10},
                timeout=5
            )
        elif source == "google":
            r = requests.post(
                config["url"],
                headers=config["headers"],
                json={"q": query, "num": 10},
                timeout=5
            )
        else:
            return {"source": source, "error": "unknown"}
        
        r.raise_for_status()
        return {"source": source, "data": r.json()}
    
    except Exception as e:
        print(f"âš ï¸ {source} API ì—ëŸ¬: {e}")
        return {"source": source, "error": str(e)}

def filter_search_results(raw_results: List[Dict]) -> List[Dict]:
    cleaned = []
    
    for result in raw_results:
        source = result.get("source")
        data = result.get("data", {})
        
        if source == "naver":
            items = data.get("items", [])
            for item in items[:5]:
                title = re.sub(r'<[^>]+>', '', item.get("title", ""))
                desc = re.sub(r'<[^>]+>', '', item.get("description", ""))
                
                cleaned.append({
                    "source": source,
                    "title": title,
                    "link": item.get("link", ""),
                    "snippet": desc,
                    "address": item.get("address", ""),
                })
        
        elif source == "google":
            items = data.get("organic", [])
            for item in items[:5]:
                cleaned.append({
                    "source": source,
                    "title": item.get("title", ""),
                    "link": item.get("link", ""),
                    "snippet": item.get("snippet", ""),
                })
    
    return cleaned

def fetch_image_with_cache(name: str, category: SearchCategory, source_url: str = "") -> str:
    hash_val = image_cache.get_hash(name, source_url)
    
    cached_url = image_cache.get_url(hash_val, full_url=True)
    if cached_url:
        print(f"âœ… [ì´ë¯¸ì§€ ìºì‹œ íˆíŠ¸] {name}")
        return cached_url
    
    print(f"ğŸ“¥ [ì´ë¯¸ì§€ ìºì‹œ ì—†ìŒ] {name} â†’ NAVER ê²€ìƒ‰ ì‹œì‘")
    
    if NAVER_ID and NAVER_SECRET:
        try:
            resp = requests.get(
                "https://openapi.naver.com/v1/search/image",
                headers={
                    "X-Naver-Client-Id": NAVER_ID,
                    "X-Naver-Client-Secret": NAVER_SECRET,
                },
                params={
                    "query": f"{name} {category.value}",
                    "display": 1,
                    "sort": "sim",
                    "filter": "small"
                },
                timeout=3
            )
            
            if resp.status_code == 200:
                data = resp.json()
                items = data.get("items", [])
                
                if items:
                    img_url = items[0].get("link")
                    saved_url = image_cache.save(hash_val, img_url)
                    
                    if saved_url:
                        print(f"ğŸ’¾ [ì´ë¯¸ì§€ ìºì‹œ ì €ì¥] {name}")
                        return saved_url
                        
        except Exception as e:
            print(f"âš ï¸ [NAVER ì´ë¯¸ì§€ ê²€ìƒ‰ ì˜¤ë¥˜] {name}: {e}")
    
    print(f"ğŸ¨ [Placeholder ì‚¬ìš©] {name}")
    seed = abs(hash(name)) % 1000
    return f"https://placehold.co/400x400/e0e0e0/666666?text={name[:2]}"

def generate_prompt(category: SearchCategory, query: str, results: List[Dict]) -> str:
    schema = CATEGORY_SCHEMAS.get(category, CATEGORY_SCHEMAS[SearchCategory.GENERAL])
    
    fields_desc = []
    for f in schema["fields"]:
        req = "í•„ìˆ˜" if f["required"] else "ì„ íƒ"
        fields_desc.append(f"- {f['name']} ({f['type']}): {req}")
    
    context = []
    for r in results[:12]:
        context.append({
            "title": r.get("title", ""),
            "snippet": r.get("snippet", "")[:150],
            "source": r.get("source", ""),
            "link": r.get("link", ""),
        })
    
    return f"""# ì‚¬ìš©ì ì¿¼ë¦¬
{query}

# ì¹´í…Œê³ ë¦¬
{category.value}

# ì¶œë ¥ í˜•ì‹
ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆì— ë§ì¶° **ì •í™•íˆ {schema['count']}ê°œ**ì˜ ê²°ê³¼ë¥¼ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

## í•„ë“œ
{chr(10).join(fields_desc)}

## ë­í‚¹ ê¸°ì¤€
{', '.join(schema['ranking'])} ìˆœìœ¼ë¡œ ìƒìœ„ {schema['count']}ê°œ ì„ ì •

# ê²€ìƒ‰ ê²°ê³¼
{json.dumps(context, ensure_ascii=False, indent=2)}

**ì¤‘ìš”:**
1. ì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥
2. ì •í™•íˆ {schema['count']}ê°œ
3. í•„ìˆ˜ í•„ë“œ í¬í•¨
4. ì¤‘ë³µ ì œê±°
5. Summary: ì¢…í•©ì ì´ê³  ê°ê´€ì ì¸ 2~3ë¬¸ì¥ ìš”ì•½"""

def generate_system_instruction(category: SearchCategory) -> str:
    schema = CATEGORY_SCHEMAS.get(category, CATEGORY_SCHEMAS[SearchCategory.GENERAL])
    
    return f"""ë‹¹ì‹ ì€ {category.value} ê²€ìƒ‰ ì „ë¬¸ AIì…ë‹ˆë‹¤.

ê·œì¹™:
- ì˜¤ì§ ìœ íš¨í•œ JSON ë°°ì—´ë§Œ ì¶œë ¥
- ë§ˆí¬ë‹¤ìš´, ì„¤ëª…, ì£¼ì„ ê¸ˆì§€
- {schema['ranking']} ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
- ì •í™•íˆ {schema['count']}ê°œ ìƒì„±"""

def clean_json_response(text: str) -> str:
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```\s*', '', text)
    match = re.search(r'\[.*\]', text, re.DOTALL)
    return match.group(0) if match else text

def sse_format(data: Dict) -> str:
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

def generate_comprehensive_response(user_input: str, cleaned: List[Dict]) -> str:
    try:
        answer_prompt = f"""ì‚¬ìš©ì ì¿¼ë¦¬: {user_input}

ìš”ì•½ ì§€ì¹¨:
- 5-7ê°œ ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€
- í•µì‹¬ ì •ë³´ ì¤‘ì‹¬
- ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹

ë¶„ì„ ì •ë³´:
{json.dumps([
    {"title": r.get("title", ""), "snippet": r.get("snippet", "")[:100]} 
    for r in cleaned[:5]
], ensure_ascii=False, indent=2)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•© ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""
        
        answer_response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=answer_prompt,
            config=types.GenerateContentConfig(
                temperature=0.1,
                max_output_tokens=300
            )
        )
        return answer_response.text.strip()
    
    except Exception as e:
        print(f"âŒ ìµœì¢… ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ì¢…í•© ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

@app.route("/stream", methods=["POST", "OPTIONS"])
def stream_search():
    if request.method == "OPTIONS":
        response = Response()
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type"
        response.headers["Access-Control-Max-Age"] = "3600"
        return response, 204

    req = request.get_json(silent=True) or {}
    user_input = req.get("query", "").strip()
    
    if not user_input:
        return Response(
            sse_format({"error": "query í•„ìˆ˜"}),
            mimetype="text/event-stream"
        )

    def generate():
        start = time.time()
        try:
            yield sse_format({"stage": "qdrant_search", "status": "started"})
            
            use_cached_results = False
            if qdrant_manager:
                query_vector = get_embedding(user_input)
                if query_vector:
                    similar_results = qdrant_manager.search_similar(query_vector, limit=3)
                    
                    if similar_results and similar_results[0]["score"] > 0.82:
                        print(f"ğŸ¯ ìœ ì‚¬ ê²€ìƒ‰ ë°œê²¬ (ì ìˆ˜: {similar_results[0]['score']:.2f})")
                        use_cached_results = True
                        yield sse_format({
                            "stage": "qdrant_search",
                            "status": "found_similar",
                            "similar_query": similar_results[0]["query"],
                            "similarity_score": similar_results[0]["score"]
                        })
            
            yield sse_format({"stage": "qdrant_search", "status": "finished"})

            yield sse_format({"stage": "classify", "status": "started"})
            category, clean_query = classify_query(user_input)
            yield sse_format({
                "stage": "classify",
                "status": "finished",
                "category": category.value,
            })

            yield sse_format({"stage": "search", "status": "started"})
            
            with ThreadPoolExecutor(max_workers=2) as ex:
                naver_fut = ex.submit(fetch_api_data, "naver", clean_query)
                
                try:
                    naver_result = naver_fut.result(timeout=3)
                    raw = [naver_result]
                    print(f"âœ… NAVER ê²€ìƒ‰ ì™„ë£Œ")
                except TimeoutError:
                    print(f"â° NAVER API ì‹œê°„ ì´ˆê³¼")
                    raw = []
                
                if SERPER_KEY:
                    google_fut = ex.submit(fetch_api_data, "google", clean_query)
                    try:
                        google_result = google_fut.result(timeout=3)
                        raw.append(google_result)
                        print(f"âœ… Google ê²€ìƒ‰ ì™„ë£Œ")
                    except TimeoutError:
                        print(f"â° Google API ì‹œê°„ ì´ˆê³¼")
            
            yield sse_format({"stage": "search", "status": "finished"})

            yield sse_format({"stage": "filter", "status": "started"})
            cleaned = filter_search_results(raw)
            yield sse_format({"stage": "filter", "status": "finished", "count": len(cleaned)})

            yield sse_format({"stage": "synthesis", "status": "started"})
            
            prompt = generate_prompt(category, user_input, cleaned)
            system = generate_system_instruction(category)
            
            full_text = ""
            for chunk in client.models.generate_content_stream(
                model="gemini-2.0-flash",
                contents=[types.Content(
                    role="user",
                    parts=[types.Part.from_text(text=prompt)]
                )],
                config=types.GenerateContentConfig(
                    system_instruction=system,
                    response_mime_type="application/json",
                    temperature=0.2,
                    max_output_tokens=500
                ),
            ):
                if chunk.text:
                    full_text += chunk.text
            
            try:
                cleaned_json = clean_json_response(full_text)
                recommendations = json.loads(cleaned_json)
                
                if not isinstance(recommendations, list) or len(recommendations) == 0:
                    raise ValueError("ë¹ˆ ë°°ì—´")
                
                print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {len(recommendations)}ê°œ")
                
            except Exception as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}, í´ë°± ì‚¬ìš©")
                recommendations = []
                for i, item in enumerate(cleaned[:5]):
                    recommendations.append({
                        "name": item.get("title", f"ê²°ê³¼ {i+1}"),
                        "category": category.value,
                        "summary": item.get("snippet", ""),
                        "source": item.get("source", "unknown"),
                        "sourceURL": item.get("link", ""),
                        "imageUrl": "",
                    })
            
            yield sse_format({
                "stage": "synthesis",
                "status": "finished",
                "count": len(recommendations)
            })

            yield sse_format({"stage": "image_fetch", "status": "started"})
            
            for i, rec in enumerate(recommendations):
                name = rec.get("name") or rec.get("title", "")
                source_url = rec.get("sourceURL", "")
                
                rec["imageUrl"] = fetch_image_with_cache(name, category, source_url)
            
            yield sse_format({"stage": "image_fetch", "status": "finished"})

            if qdrant_manager and not use_cached_results:
                try:
                    query_vector = get_embedding(user_input)
                    if query_vector:
                        sources_data = [
                            {
                                "title": r.get("title", ""),
                                "snippet": r.get("snippet", "")[:100],
                                "link": r.get("link", ""),
                                "source": r.get("source", "")
                            }
                            for r in cleaned[:5]
                        ]
                        
                        qdrant_manager.store_search(
                            query=user_input,
                            category=category.value,
                            vector=query_vector,
                            recommendations=recommendations,
                            sources=sources_data
                        )
                        print(f"âœ… Qdrantì— ê²€ìƒ‰ ê²°ê³¼ ë©”íƒ€ë°ì´í„° ì €ì¥")
                except Exception as e:
                    print(f"âš ï¸ Qdrant ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

            # ì¢…í•© ë‹µë³€ ìƒì„±
            answer_summary = generate_comprehensive_response(user_input, cleaned)

            duration = round(time.time() - start, 2)
            yield sse_format({
                "stage": "complete",
                "status": "finished",
                "category": category.value,
                "duration_sec": duration,
                "recommendations": recommendations,
                "answer_summary": answer_summary,
                "from_cache": use_cached_results,
                "sources": [
                    {
                        "title": r.get("title", ""),
                        "snippet": r.get("snippet", "")[:100],
                        "link": r.get("link", ""),
                        "source": r.get("source", "")
                    }
                    for r in cleaned[:5]
                ]
            })

        except Exception as e:
            trace = traceback.format_exc()
            print(f"âŒ ì—ëŸ¬: {e}\n{trace}")
            yield sse_format({
                "stage": "error",
                "error": str(e),
            })

    return Response(
        generate(),
        mimetype="text/event-stream",
        headers={
            "Access-Control-Allow-Origin": "*",
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        }
    )

@app.route("/images/<filename>")
def serve_image(filename):
    """ë¡œì»¬ ì´ë¯¸ì§€ ì„œë¹™ (GCS ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”)"""
    if USE_GCS:
        return jsonify({"error": "GCS ì‚¬ìš© ì¤‘, ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” í•„ìš” ì—†ìŠµë‹ˆë‹¤"}), 404
    return send_from_directory(image_cache.cache_dir, filename)

@app.route("/health", methods=["GET"])
def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ - ëª¨ë‹ˆí„°ë§ ë° ë¡œë“œ ë°¸ëŸ°ì„œìš©"""
    try:
        cache_info = {}
        
        if USE_GCS:
            try:
                bucket = gcs_client.bucket(GCS_BUCKET_NAME)
                blobs = list(bucket.list_blobs(prefix="images/"))
                cache_info["type"] = "gcs"
                cache_info["image_count"] = len(blobs)
                cache_info["status"] = "ok"
            except Exception as e:
                cache_info["type"] = "gcs"
                cache_info["status"] = "error"
                cache_info["error"] = str(e)
        else:
            if os.path.exists(image_cache.cache_dir):
                cache_info["type"] = "local"
                cache_info["image_count"] = len([f for f in os.listdir(image_cache.cache_dir) if f.endswith('.jpg')])
                cache_info["status"] = "ok"
            else:
                cache_info["type"] = "local"
                cache_info["status"] = "no_cache_dir"
        
        return jsonify({
            "status": "ok",
            "timestamp": datetime.now().isoformat(),
            "services": {
                "gemini": client is not None,
                "qdrant": qdrant_manager is not None,
                "naver": NAVER_ID is not None,
                "gcs": USE_GCS,
            },
            "cache": cache_info,
        }), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
        }), 500

@app.route("/cleanup-cache", methods=["POST"])
def cleanup_cache():
    """ìˆ˜ë™ìœ¼ë¡œ ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ (ê´€ë¦¬ììš©)"""
    try:
        days = request.get_json(silent=True).get("days", 30) if request.get_json(silent=True) else 30
        image_cache.cleanup_old_cache(days=days)
        
        return jsonify({
            "status": "success",
            "message": f"{days}ì¼ ì´ìƒ ëœ ìºì‹œë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat(),
        }), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e),
        }), 500

if __name__ == "__main__":
    print("ğŸš€ AllimPom ì„œë²„ ì‹œì‘...")
    print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ì†Œ: {'GCS' if USE_GCS else 'ë¡œì»¬'}")
    print(f"ğŸ”µ Qdrant: {'ì—°ê²°ë¨' if qdrant_manager else 'ì—°ê²° ì•ˆ ë¨'}")
    
    # ì‹œì‘ ì‹œ í•œ ë²ˆ ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬
    print("ğŸ§¹ ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ ì¤‘...")
    image_cache.cleanup_old_cache(days=30)
    
    app.run(
        host="0.0.0.0",
        port=int(os.environ.get("PORT", 8080)),
        debug=False,
        threaded=True
    )