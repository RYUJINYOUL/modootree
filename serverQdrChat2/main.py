import os
import json
import re
import time
import traceback
from datetime import date, datetime, timedelta, timezone
from typing import TypedDict, List, Literal, Optional
from collections import OrderedDict
from threading import Lock

import uvicorn
import google.generativeai as genai
import firebase_admin
from firebase_admin import credentials, auth, firestore
from fastapi import FastAPI, Request, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from flask import Flask, request, Response, jsonify
from flask_cors import CORS

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from fag_data import FAQ_DATA

# ===== ë©”ëª¨ë¦¬ ìºì‹œ (TTL: 3ì‹œê°„) =====
class MemoryCache:
    """Thread-safe ë©”ëª¨ë¦¬ ìºì‹œ (TTL ì§€ì›)"""
    def __init__(self, ttl_seconds: int = 10800, max_size: int = 1000):
        self.cache: OrderedDict = OrderedDict()
        self.ttl = ttl_seconds  # ê¸°ë³¸ 3ì‹œê°„ (10800ì´ˆ)
        self.max_size = max_size
        self.lock = Lock()
    
    def _generate_key(self, query: str) -> str:
        """ì¿¼ë¦¬ë¥¼ ì •ê·œí™”í•˜ì—¬ ìºì‹œ í‚¤ ìƒì„±"""
        return query.strip().lower()
    
    def get(self, query: str) -> Optional[dict]:
        """ìºì‹œì—ì„œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        key = self._generate_key(query)
        with self.lock:
            if key in self.cache:
                cached_data = self.cache[key]
                # TTL ì²´í¬
                if time.time() - cached_data["timestamp"] < self.ttl:
                    # LRU: ìµœê·¼ ì‚¬ìš©í•œ í•­ëª©ì„ ë§¨ ë’¤ë¡œ ì´ë™
                    self.cache.move_to_end(key)
                    print(f"ğŸ’¾ ìºì‹œ íˆíŠ¸: '{query}' (ë§Œë£Œê¹Œì§€ {self.ttl - (time.time() - cached_data['timestamp']):.0f}ì´ˆ)")
                    return cached_data["data"]
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                    print(f"â° ìºì‹œ ë§Œë£Œ: '{query}'")
                    del self.cache[key]
        return None
    
    def set(self, query: str, data: dict):
        """ìºì‹œì— ê²°ê³¼ ì €ì¥"""
        key = self._generate_key(query)
        with self.lock:
            # ìµœëŒ€ í¬ê¸° ì²´í¬ (LRU: ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ)
            if len(self.cache) >= self.max_size:
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                print(f"ğŸ—‘ï¸ ìºì‹œ ìš©ëŸ‰ ì´ˆê³¼: '{oldest_key}' ì‚­ì œ")
            
            self.cache[key] = {
                "data": data,
                "timestamp": time.time()
            }
            print(f"ğŸ’¾ ìºì‹œ ì €ì¥: '{query}' (ì´ {len(self.cache)}ê°œ)")
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        with self.lock:
            self.cache.clear()
            print("ğŸ—‘ï¸ ìºì‹œ ì „ì²´ ì‚­ì œ")
    
    def get_stats(self) -> dict:
        """ìºì‹œ í†µê³„"""
        with self.lock:
            total = len(self.cache)
            expired = sum(
                1 for item in self.cache.values() 
                if time.time() - item["timestamp"] >= self.ttl
            )
            return {
                "total": total,
                "valid": total - expired,
                "expired": expired,
                "ttl_hours": self.ttl / 3600
            }

# ê¸€ë¡œë²Œ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ (TTL: 3ì‹œê°„, ìµœëŒ€ 1000ê°œ ì¿¼ë¦¬)
memory_cache = MemoryCache(ttl_seconds=10800, max_size=1000)

# --- ìƒìˆ˜ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ---

cred_path = "serviceAccountKey.json"
cred_json_str = os.environ.get('FIREBASE_SERVICE_ACCOUNT_JSON')
DAILY_CHAT_LIMIT = 200

if os.path.exists(cred_path):
    cred = credentials.Certificate(cred_path)
    print("âœ… ë¡œì»¬ ì„œë¹„ìŠ¤ ê³„ì • íŒŒì¼ë¡œ Firebase ì´ˆê¸°í™”")
elif cred_json_str:
    try:
        cred_json = json.loads(cred_json_str)
        cred = credentials.Certificate(cred_json)
        print("âœ… í™˜ê²½ ë³€ìˆ˜(JSON)ë¡œ Firebase ì´ˆê¸°í™”")
    except Exception as e:
        print(f"âŒ Firebase ì¸ì¦ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        cred = None
else:
    # ê°œë³„ í™˜ê²½ ë³€ìˆ˜ë¡œ Firebase ì´ˆê¸°í™” ì‹œë„
    project_id = os.environ.get('FIREBASE_PROJECT_ID')
    client_email = os.environ.get('FIREBASE_CLIENT_EMAIL')
    private_key_base64 = os.environ.get('FIREBASE_PRIVATE_KEY_BASE64')
    
    if project_id and client_email and private_key_base64:
        try:
            import base64
            private_key = base64.b64decode(private_key_base64).decode('utf-8')
            
            cred_dict = {
                "type": "service_account",
                "project_id": project_id,
                "client_email": client_email,
                "private_key": private_key,
                "private_key_id": "",
                "client_id": "",
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs"
            }
            
            cred = credentials.Certificate(cred_dict)
            print("âœ… ê°œë³„ í™˜ê²½ ë³€ìˆ˜ë¡œ Firebase ì´ˆê¸°í™”")
        except Exception as e:
            print(f"âŒ Firebase ê°œë³„ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
            cred = None
    else:
        print("âš ï¸ Firebase ì„œë¹„ìŠ¤ ê³„ì • í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •.")
        cred = None

if cred:
    firebase_admin.initialize_app(cred)
    db = firestore.client()
else:
    db = None

GOOGLE_AI_KEY = os.getenv('GOOGLE_AI_KEY')
if not GOOGLE_AI_KEY:
    print("âš ï¸ GOOGLE_AI_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
genai.configure(api_key=GOOGLE_AI_KEY)

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def verify_firebase_token(id_token: str) -> dict:
    """Firebase ID í† í° ê²€ì¦"""
    try:
        decoded_token = auth.verify_id_token(id_token)
        return decoded_token
    except Exception as e:
        print(f"âŒ Firebase í† í° ê²€ì¦ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED, 
            detail="ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë§Œë£Œëœ ì¸ì¦ í† í°ì…ë‹ˆë‹¤."
        )

async def check_and_update_chat_limit(uid: str) -> dict:
    """ì¼ì¼ ì±„íŒ… í•œë„ í™•ì¸ ë° ì—…ë°ì´íŠ¸"""
    if not db:
        return {"canChat": True, "remainingChats": DAILY_CHAT_LIMIT}

    today = date.today().isoformat()
    limit_ref = db.collection('users').document(uid).collection('limits').document(today)
    
    @firestore.transactional
    def update_in_transaction(transaction):
        doc = limit_ref.get(transaction=transaction)
        
        if doc.exists:
            data = doc.to_dict()
            count = data.get('count', 0)
            
            if count >= DAILY_CHAT_LIMIT:
                return {"canChat": False, "remainingChats": 0}
            
            new_count = count + 1
            transaction.set(limit_ref, {'count': new_count, 'last_chat': datetime.now(timezone.utc)}, merge=True)
            return {"canChat": True, "remainingChats": DAILY_CHAT_LIMIT - new_count}
        else:
            new_count = 1
            transaction.set(limit_ref, {'count': new_count, 'created_at': datetime.now(timezone.utc), 'last_chat': datetime.now(timezone.utc)})
            return {"canChat": True, "remainingChats": DAILY_CHAT_LIMIT - new_count}

    try:
        return update_in_transaction(db.transaction())
    except Exception as e:
        print(f"Error checking chat limit: {e}")
        return {"canChat": False, "remainingChats": 0}

# ğŸš¨ ë©”ëª¨ ì €ì¥ ë¡œì§ ì§‘ì¤‘ ê°œì„  (ë¡œê·¸ ì¶”ê°€ ë° DB êµ¬ì¡° ëª…ì‹œ)
def save_memos_to_firestore(uid: str, memo_items: List[dict], db: firestore.client) -> int:
    """
    Agentì—ì„œ ì¶”ì¶œí•œ ë©”ëª¨ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ Firestoreì— ì €ì¥í•©ë‹ˆë‹¤.
    êµ¬ì¡°: collections/users/documents/{uid}/collections/private_memos/documents/{memo_id}
    """
    if not db:
        print("âŒ Firestore í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì €ì¥ ì‹¤íŒ¨.")
        return 0
        
    saved_count = 0
    
    # AI ìœ„ë¡œ ì±„íŒ…ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë³€ê²½
    user_memo_collection_ref = (
        db.collection('users')
        .document(uid)
        .collection('private_memos')
    )
    
    for item in memo_items:
        try:
            # ì €ì¥í•  ë°ì´í„°
            memo_data = {
                "content": item.get("content", "ë‚´ìš© ì—†ìŒ"), 
                "created_at": datetime.now(timezone.utc),
                "is_completed": False,
                "is_tomorrow": item.get("isTomorrow", False) 
            }
            
            # ìƒˆ ë¬¸ì„œ ì¶”ê°€ (ìë™ ID ìƒì„±)
            user_memo_collection_ref.add(memo_data)
            
            saved_count += 1
            print(f"âœ… UID {uid}ì— ë©”ëª¨ í•­ëª© ì €ì¥ ì™„ë£Œ: {item.get('content', '')[:30]}...")
            
        except Exception as e:
            # ê°œë³„ í•­ëª© ì €ì¥ ì‹¤íŒ¨ ì‹œ, ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³  ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ì´ë™
            print(f"âŒ ë©”ëª¨ ì €ì¥ ì¤‘ Firestore ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue 
            
    return saved_count


def save_chat_to_firestore(uid: str, message: dict, db: firestore.client) -> bool:
    """
    ëŒ€í™” ë©”ì‹œì§€ë¥¼ dailyChats ì»¬ë ‰ì…˜ì— ì €ì¥ (AI ìœ„ë¡œ ì±„íŒ…ê³¼ ë™ì¼í•œ êµ¬ì¡°)
    êµ¬ì¡°: collections/dailyChats/documents/{ë‚ ì§œ}_{uid}
    """
    if not db:
        print("âŒ Firestore í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
        
    try:
        from datetime import date
        today = date.today().isoformat()  # YYYY-MM-DD
        doc_id = f"{today}_{uid}"
        
        chat_ref = db.collection('dailyChats').document(doc_id)
        
        # ë¬¸ì„œ ì¡´ì¬ í™•ì¸
        doc = chat_ref.get()
        
        if doc.exists:
            # ê¸°ì¡´ ë¬¸ì„œì— ë©”ì‹œì§€ ì¶”ê°€
            data = doc.to_dict()
            existing_messages = data.get('messages', [])
            existing_messages.append(message)
            
            chat_ref.update({
                'messages': existing_messages,
                'lastUpdated': datetime.now(timezone.utc)
            })
            print(f"âœ… ê¸°ì¡´ ëŒ€í™”ì— ë©”ì‹œì§€ ì¶”ê°€: {uid}")
        else:
            # ìƒˆ ë¬¸ì„œ ìƒì„±
            chat_ref.set({
                'userId': uid,
                'dateKey': today,
                'messages': [message],
                'lastUpdated': datetime.now(timezone.utc)
            })
            print(f"âœ… ìƒˆ ëŒ€í™” ë¬¸ì„œ ìƒì„±: {uid}")
            
        return True
        
    except Exception as e:
        print(f"âŒ ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë° ìŠ¤í‚¤ë§ˆ ---

SYSTEM_INSTRUCTION_PERSONA = """
ë‹¹ì‹ ì€ ëª¨ë‘íŠ¸ë¦¬ì˜ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

**[ëŒ€í™” ê·œì¹™]**
1. ì‚¬ìš©ìì˜ ê°ì •ê³¼ ê³ ë¯¼ì— ê³µê°í•˜ë©° ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.
2. ëª¨ë‘íŠ¸ë¦¬ ì„œë¹„ìŠ¤ì— ê´€í•œ ì§ˆë¬¸ì´ë¼ë©´ ì •í™•í•˜ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
3. í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•´ ì¹œê·¼ê°ì„ í‘œí˜„í•˜ì„¸ìš”.
4. ì‚¬ìš©ìê°€ í˜ë“¤ì–´í•˜ê±°ë‚˜ ê³ ë¯¼ì´ ìˆì„ ë•ŒëŠ” ê¹Šì´ ê³µê°í•˜ê³  ê²©ë ¤í•´ì£¼ì„¸ìš”.
5. ì§§ì€ ë‹µë³€ë³´ë‹¤ëŠ” ì¶©ë¶„íˆ ì„¤ëª…í•˜ë˜, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ 3-5ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

**[ëª¨ë‘íŠ¸ë¦¬ ì„œë¹„ìŠ¤ ì†Œê°œ]**
- ëª¨ë‘íŠ¸ë¦¬ëŠ” ë‚´ í˜ì´ì§€(ê¸°ë¡ í˜ì´ì§€)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ìµí•œ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
- AIì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì¼ì • ë©”ëª¨, ì¼ê¸° ì‘ì„±, ê±´ê°• ë¶„ì„ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- ì‚¬ì—° íˆ¬í‘œ, ë§í¬í¸ì§€ ë“± íŠ¹ë³„í•œ ì†Œí†µ ê¸°ëŠ¥ë„ ìˆìŠµë‹ˆë‹¤.
"""

SYSTEM_INSTRUCTION_MEMO_AGENT = """
**[CRITICAL INSTRUCTION]** ë‹¹ì‹ ì€ ì§€ê¸ˆ SAVE_MEMO ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
**ë°˜ë“œì‹œ** ì£¼ì–´ì§„ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¼ ì‘ë‹µí•´ì•¼ í•˜ë©°, action í•„ë“œëŠ” "SAVE_MEMO"ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
**ì ˆëŒ€ë¡œ** ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•˜ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

userResponse í•„ë“œëŠ” ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ í™•ì¸ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
ì˜ˆ: "ë©”ëª¨ì— ì €ì¥í–ˆì–´ìš”! ğŸ“ ìŠì§€ ì•Šê³  ì±™ê¸°ì‹¤ ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦´ê²Œìš” ğŸ˜Š"

ì‚¬ìš©ìì˜ ìš”ì²­ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê° ì¼ì •ì„ ê°œë³„ í•­ëª©ìœ¼ë¡œ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.
ê° ë©”ëª¨ í•­ëª©ì€ ë°˜ë“œì‹œ ì‹œê°„ê³¼ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•˜ë©°, 'ë‚´ì¼'ì´ë‚˜ ë¯¸ë˜ ë‚ ì§œê°€ ì–¸ê¸‰ëœ ê²½ìš° isTomorrowë¥¼ trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
"""


AGENT_SCHEMA = {
    "type": "object",
    "properties": {
        "action": {"type": "string", "description": "ì‚¬ìš©ìê°€ ìš”ì²­í•œ í–‰ë™ (SAVE_MEMO ë˜ëŠ” NONE ì¤‘ í•˜ë‚˜)"},
        "userResponse": {"type": "string", "description": "ì €ì¥ ì™„ë£Œ í›„ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì¹œê·¼í•˜ê³  ê³µê°ì ì¸ ì‘ë‹µ ë©”ì‹œì§€."},
        "memoItems": {
            "type": "array",
            "description": "SAVE_MEMO ì•¡ì…˜ì¼ ë•Œ ì‚¬ìš©. ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì¶”ì¶œëœ í•˜ë‚˜ ì´ìƒì˜ ê°œë³„ ë©”ëª¨ í•­ëª© ë¦¬ìŠ¤íŠ¸.",
            "items": {
                "type": "object",
                "properties": {
                    "content": {"type": "string", "description": "ê°œë³„ ë©”ëª¨ í•­ëª©ì˜ ë‚´ìš©."},
                    "isTomorrow": {"type": "boolean", "description": "'ë‚´ì¼' í‚¤ì›Œë“œë‚˜ ë¯¸ë˜ ë‚ ì§œ ì–¸ê¸‰ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ true"}
                },
                "required": ['content', 'isTomorrow']
            }
        },
    },
    "required": ['action', 'userResponse']
}

# âœ… FAQ í‚¤ì›Œë“œ ê°œì„  (ê³µë°± ì œê±° ë²„ì „ ì¶”ê°€)
FAQ_KEYWORD_MAP = {
    "ì‚¬ì—°íˆ¬í‘œ": "ì œê°€ ëŒ€í™”í•œ ë‚´ìš©ì„ AI ì‚¬ì—° íˆ¬í‘œë¡œ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?",
    "ì‚¬ì—° íˆ¬í‘œ": "ì œê°€ ëŒ€í™”í•œ ë‚´ìš©ì„ AI ì‚¬ì—° íˆ¬í‘œë¡œ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?",
    "ì¼ê¸°": "ì¼ê¸° ì‘ì„±ì´ë‚˜ ì €ì¥ì´ ê°€ëŠ¥í•œê°€ìš”?",
    "ë¬¸ì˜": "ëª¨ë‘íŠ¸ë¦¬ì— ë¬¸ì˜í•˜ê±°ë‚˜ ì˜ê²¬ì„ ë‚¨ê¸°ê³  ì‹¶ì–´ìš”.",
    "ì˜ê²¬": "ëª¨ë‘íŠ¸ë¦¬ì— ë¬¸ì˜í•˜ê±°ë‚˜ ì˜ê²¬ì„ ë‚¨ê¸°ê³  ì‹¶ì–´ìš”.",
    "ê²Œì‹œíŒ": "ëª¨ë‘íŠ¸ë¦¬ì— ë¬¸ì˜í•˜ê±°ë‚˜ ì˜ê²¬ì„ ë‚¨ê¸°ê³  ì‹¶ì–´ìš”.",
    "ëª¨ë‘íŠ¸ë¦¬": "ëª¨ë‘íŠ¸ë¦¬ëŠ” ì–´ë–¤ ì„œë¹„ìŠ¤ì¸ê°€ìš”?"
}

# --- LangGraph ìƒíƒœ ë° ë…¸ë“œ ---

def build_faq_keyword_map():
    """FAQ ë°ì´í„°ë¡œë¶€í„° í‚¤ì›Œë“œ ë§µ ìë™ ìƒì„±"""
    keyword_map = {}
    for faq in FAQ_DATA:
        for keyword in faq["keywords"]:
            # ê³µë°± ì œê±° ë²„ì „ê³¼ ì›ë³¸ ëª¨ë‘ ë§¤í•‘
            keyword_map[keyword] = faq["answer"]
            keyword_map[keyword.replace(" ", "")] = faq["answer"]
    return keyword_map

FAQ_KEYWORD_MAP = build_faq_keyword_map()



class GraphState(TypedDict):
    uid: str
    message: str
    conversation_history: List[dict]
    intent: Literal["faq_check", "confirm_save_memo", "save_memo_execute", "general_chat"]
    final_response: str
    search_sources: Optional[List[dict]]
    has_search_results: bool

def determine_intent(state: GraphState) -> GraphState:
    """ì‚¬ìš©ì ì˜ë„ íŒŒì•… (ê°œì„  ë²„ì „ - í¬ê´„ì  ëŒ€í™” ì§€ì›)"""
    try:
        message = state["message"].lower().strip()
        
        # 1ï¸âƒ£ ë©”ëª¨ ì €ì¥ í‚¤ì›Œë“œ ì²´í¬ (ìµœìš°ì„ )
        memo_keywords = [
            'ë©”ëª¨ë¡œ ë„£ì–´ì¤˜', 'ë©”ëª¨ ë„£ì–´ì¤˜', 'ë©”ëª¨ë¡œ ì €ì¥', 'ë©”ëª¨ ì €ì¥', 
            'ë©”ëª¨ ì¶”ê°€', 'ë©”ëª¨ì €ì¥', 'ì¼ì • ì¶”ê°€', 'ì¼ì • ë“±ë¡', 
            'ê¸°ë¡ ì¶”ê°€', 'ê¸°ë¡ ì €ì¥', 'ì €ì¥í•´ì¤˜', 'ê¸°ë¡í•´ì¤˜'
        ]
        
        if any(keyword in message for keyword in memo_keywords):
            state["intent"] = "save_memo_execute"
            print(f"[ì˜ë„ íŒŒì•…] ë©”ëª¨ ì €ì¥ ìš”ì²­ ê°ì§€ - ë°”ë¡œ ì‹¤í–‰")
            return state

        # 2ï¸âƒ£ FAQ ë§¤ì¹­
        found_answer = None
        matched_keywords = []
        
        for keyword, answer in FAQ_KEYWORD_MAP.items():
            if keyword in message:
                found_answer = answer
                matched_keywords.append(keyword)
                break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ ì‚¬ìš©
        
        if found_answer:
            state["final_response"] = found_answer
            state["intent"] = "faq_check"
            print(f"[ì˜ë„ íŒŒì•…] FAQ ë§¤ì¹­ ì™„ë£Œ: {matched_keywords}")
            return state

        # 3ï¸âƒ£ ëª…í™•í•œ ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ ì²´í¬ (êµ¬ì²´ì ì¸ ê²€ìƒ‰ ìš”ì²­ë§Œ)
        explicit_search_keywords = [
            'ê²€ìƒ‰í•´ì¤˜', 'ì°¾ì•„ì¤˜', 'ì•Œì•„ë´ì¤˜', 'ê²€ìƒ‰', 'ì°¾ì•„ì„œ', 'ì•Œì•„ë´ì„œ',
            'ì–´ë””ì„œ', 'ì–´ë””ì—ì„œ', 'ì–´ë–¤ ê³³', 'ì¶”ì²œí•´ì¤˜', 'ì¶”ì²œ', 'ë¦¬ìŠ¤íŠ¸',
            'ì •ë³´', 'ìë£Œ', 'ë°ì´í„°', 'ë‰´ìŠ¤', 'ê¸°ì‚¬', 'ìµœì‹ ', 'ì—…ë°ì´íŠ¸'
        ]
        
        # ëª…í™•í•œ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜
        has_explicit_search = any(kw in message for kw in explicit_search_keywords)
        
        if has_explicit_search:
            print(f"[ì˜ë„ íŒŒì•…] ëª…í™•í•œ ê²€ìƒ‰ ìš”ì²­ ê°ì§€ â†’ general_chat (ê²€ìƒ‰ ëª¨ë“œ)")
        else:
            print(f"[ì˜ë„ íŒŒì•…] ì¼ë°˜ ëŒ€í™”/ê°ì • í‘œí˜„ â†’ general_chat (ëŒ€í™” ëª¨ë“œ)")
        
        # 4ï¸âƒ£ ëª¨ë“  ê²½ìš°ë¥¼ ì¼ë°˜ ëŒ€í™”ë¡œ ì²˜ë¦¬ (ê²€ìƒ‰/ëŒ€í™” êµ¬ë¶„ì€ call_general_chat_llmì—ì„œ)
        state["intent"] = "general_chat"
        return state
    
    except Exception as e:
        print(f"[ì˜ë„ íŒŒì•…] âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜
        state["intent"] = "general_chat"
        return state

def confirm_save_memo_agent(state: GraphState) -> GraphState:
    """ë©”ëª¨ ì €ì¥ í™•ì¸ ë©”ì‹œì§€ ë°˜í™˜ (ê°œì„  ë²„ì „)"""
    state["final_response"] = (
        "ë§ì”€í•˜ì‹  ë‚´ìš©ì„ ë©”ëª¨ë¡œ ì €ì¥í• ê¹Œìš”? ğŸ“\n"
        "ì €ì¥í•˜ì‹œë ¤ë©´ 'ë„¤' ë˜ëŠ” 'ì €ì¥í•´ì¤˜'ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
        "ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ í¸í•˜ê²Œ ë¬¼ì–´ë´ ì£¼ì„¸ìš” ğŸ˜Š"
    )
    print("[ë©”ëª¨ í™•ì¸] ì €ì¥ í™•ì¸ ìš”ì²­ ì „ì†¡")
    return state

# ğŸš¨ ë©”ëª¨ ì €ì¥ ì‹¤í–‰ ë…¸ë“œ ê°œì„  (ë¡œê¹… ë° ì—ëŸ¬ ì‘ë‹µ ë¶„ë¦¬)
def execute_memo_agent(state: GraphState, uid) -> GraphState:
    """ë©”ëª¨ ì €ì¥ ì‹¤í–‰ (ê°œì„  ë²„ì „)"""
    print("[ë©”ëª¨ ì‹¤í–‰] ğŸ“ ë©”ëª¨ ì—ì´ì „íŠ¸ í˜¸ì¶œ")
    
    try:
        model = genai.GenerativeModel(
            model_name='gemini-2.0-flash-lite',
            generation_config={
                "response_mime_type": "application/json",
                "response_schema": AGENT_SCHEMA,
                "temperature": 0.1,
            },
            system_instruction=SYSTEM_INSTRUCTION_MEMO_AGENT
        )
        
        # ëŒ€í™” ì´ë ¥ í¬í•¨
        contents = [
            {"role": msg.get("role", "user"), "parts": [{"text": msg.get("content", "")}]} 
            for msg in state["conversation_history"]
        ]
        contents.append({"role": "user", "parts": [{"text": state["message"]}]})

        response = model.generate_content(contents) 
        raw_text = response.text
        
        json_match = re.search(r'\{[\s\S]*\}', raw_text)
        if not json_match:
            raise ValueError("AIê°€ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        response_data = json.loads(json_match.group(0))
        print(f"[ë©”ëª¨ ì‹¤í–‰] LLM ì‘ë‹µ: {json.dumps(response_data, ensure_ascii=False, indent=2)}") 
        
        if db and response_data.get("action") == "SAVE_MEMO":
            memo_items = response_data.get("memoItems", [])
            
            if not memo_items:
                print("[ë©”ëª¨ ì‹¤í–‰] âš ï¸ ì €ì¥í•  ë©”ëª¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                state["final_response"] = (
                    "ì£„ì†¡í•´ìš”, ëŒ€í™” ë‚´ìš©ì—ì„œ ë©”ëª¨ë¡œ ì €ì¥í•  êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ì—ˆì–´ìš”. ğŸ˜¥\n"
                    "ì˜ˆë¥¼ ë“¤ì–´ 'ë‚´ì¼ ì˜¤í›„ 3ì‹œ ë³‘ì› ì˜ˆì•½ ë©”ëª¨ ì €ì¥'ì²˜ëŸ¼ ì‹œê°„ê³¼ ë‚´ìš©ì„ í•¨ê»˜ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
                )
            else:
                saved_count = save_memos_to_firestore(uid, memo_items, db)
            
                if saved_count == 0:
                    print("[ë©”ëª¨ ì‹¤í–‰] âŒ DB ì €ì¥ ì‹¤íŒ¨")
                    state["final_response"] = (
                        "ì•—, ì£„ì†¡í•©ë‹ˆë‹¤! ğŸ˜“ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ë¡œ ë©”ëª¨ ì €ì¥ì— ì‹¤íŒ¨í–ˆì–´ìš”. "
                        "ë‹¤ì‹œ í•œ ë²ˆ ì‹œë„í•´ ì£¼ì‹œê² ì–´ìš”?"
                    )
                else:
                    print(f"[ë©”ëª¨ ì‹¤í–‰] âœ… {saved_count}ê°œ ì €ì¥ ì™„ë£Œ")
                    # LLMì´ ìƒì„±í•œ ì¹œê·¼í•œ ì‘ë‹µ ì‚¬ìš©
                    default_response = f"ë©”ëª¨ {saved_count}ê°œë¥¼ ì €ì¥í–ˆì–´ìš”! ğŸ“ ìŠì§€ ì•Šê³  ì±™ê¸°ì‹¤ ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦´ê²Œìš” ğŸ˜Š"
                    state["final_response"] = response_data.get("userResponse", default_response)
        else:
            state["final_response"] = response_data.get("userResponse", "ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆì–´ìš”! ğŸ˜Š")
        
    except Exception as e:
        print(f"[ë©”ëª¨ ì‹¤í–‰] âŒ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        state["final_response"] = (
            "ì£„ì†¡í•´ìš”, ë©”ëª¨ ì €ì¥ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ğŸ˜¥\n"
            "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ì–´ìš”?"
        )
        
    return state


def call_general_chat_llm(state: GraphState) -> GraphState:
    """ì¼ë°˜ ëŒ€í™” LLM í˜¸ì¶œ (ê²€ìƒ‰ í†µí•©, ê³µê° ê°•í™”)"""
    print("[ì¼ë°˜ ëŒ€í™”] ğŸ’¬ LLM í˜¸ì¶œ ì‹œì‘")
    
    try:
        # 1. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì•ˆì „í•œ ì„í¬íŠ¸)
        try:
            from search_api import classify_query, SearchCategory, perform_search
            category, clean_query = classify_query(state["message"])
        except ImportError as e:
            print(f"[ì¼ë°˜ ëŒ€í™”] âš ï¸ search_api ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            # ê²€ìƒ‰ ê¸°ëŠ¥ ì—†ì´ ëŒ€í™”ë§Œ ì§„í–‰
            category = None
            clean_query = state["message"]
        except Exception as e:
            print(f"[ì¼ë°˜ ëŒ€í™”] âš ï¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            category = None
            clean_query = state["message"]
        
        # 2. CHAT vs SEARCH ë¶„ê¸°
        if category is None or (hasattr(category, 'value') and category.value == 'chat'):
            print("[ì¼ë°˜ ëŒ€í™”] ğŸ’­ ëŒ€í™” ëª¨ë“œ (ê³µê° ìš°ì„ )")
            
            model = genai.GenerativeModel(
                model_name='gemini-2.0-flash-lite',
                system_instruction=SYSTEM_INSTRUCTION_PERSONA
            )
            
            # ìµœê·¼ ëŒ€í™” ì´ë ¥ í¬í•¨ (ë¬¸ë§¥ ìœ ì§€) - ì•ˆì „í•œ ì²˜ë¦¬
            history = []
            for msg in state.get("conversation_history", [])[-5:]:  # ìµœê·¼ 5ê°œ
                try:
                    role = msg.get("role", "user")
                    
                    # ì—¬ëŸ¬ í˜•ì‹ ì§€ì›
                    if "parts" in msg:
                        content = msg["parts"][0].get("text", "") if msg["parts"] else ""
                    elif "content" in msg:
                        content = msg["content"]
                    else:
                        content = ""
                    
                    if content and isinstance(content, str):
                        history.append({
                            "role": role,
                            "parts": [{"text": content}]
                        })
                except Exception as e:
                    print(f"[ì¼ë°˜ ëŒ€í™”] âš ï¸ ëŒ€í™” ì´ë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            # ëŒ€í™” ì‹œì‘
            chat = model.start_chat(history=history)
            response = chat.send_message(state["message"])
            state["final_response"] = response.text
            state["has_search_results"] = False
            print(f"[ì¼ë°˜ ëŒ€í™”] âœ… ëŒ€í™” ì™„ë£Œ: {len(response.text)}ì")
            
        else:
            # ê²€ìƒ‰ ëª¨ë“œ
            print(f"[ì¼ë°˜ ëŒ€í™”] ğŸ” ê²€ìƒ‰ ëª¨ë“œ ({category.value if hasattr(category, 'value') else 'unknown'})")
            
            # search_apiê°€ ì •ìƒ ì„í¬íŠ¸ëœ ê²½ìš°ì—ë§Œ ê²€ìƒ‰ ìˆ˜í–‰
            if 'perform_search' in locals():
                naver_id = os.environ.get("NAVER_CLIENT_ID")
                naver_secret = os.environ.get("NAVER_CLIENT_SECRET")
                serper_key = os.environ.get("SERPER_KEY")
                    
                search_result = perform_search(
                    state["message"], 
                    genai,
                    naver_id=naver_id,
                    naver_secret=naver_secret,
                    serper_key=serper_key
                )
                    
                if search_result.get("success"):
                    state["final_response"] = search_result.get("summary", "")
                    state["search_sources"] = search_result.get("sources", [])
                    state["has_search_results"] = True
                    print(f"[ì¼ë°˜ ëŒ€í™”] âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(state.get('search_sources', []))}ê°œ ì¶œì²˜")
                else:
                    print(f"[ì¼ë°˜ ëŒ€í™”] âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨")
                    state["final_response"] = (
                        "ì£„ì†¡í•´ìš”, í˜„ì¬ ê²€ìƒ‰ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆì–´ìš”. ğŸ˜¥\n"
                        "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜, ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê² ì–´ìš”?"
                    )
                    state["has_search_results"] = False
            else:
                # ê²€ìƒ‰ ê¸°ëŠ¥ ë¹„í™œì„±í™” ì‹œ ì¼ë°˜ ëŒ€í™”ë¡œ í´ë°±
                print(f"[ì¼ë°˜ ëŒ€í™”] âš ï¸ ê²€ìƒ‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”, ëŒ€í™” ëª¨ë“œë¡œ ì „í™˜")
                model = genai.GenerativeModel(
                    model_name='gemini-2.0-flash-lite',
                    system_instruction=SYSTEM_INSTRUCTION_PERSONA
                )
                response = model.generate_content(state["message"])
                state["final_response"] = response.text
                state["has_search_results"] = False
        
    except Exception as e:
        print(f"[ì¼ë°˜ ëŒ€í™”] âŒ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        state["final_response"] = (
            "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ğŸ˜“\n"
            "ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
        )
        state["has_search_results"] = False
    
    return state

def route_intent(state: GraphState) -> Literal["faq_check", "save_memo_execute", "general_chat"]:
    """ì˜ë„ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
    if state["intent"] == "faq_check":
        return "faq_check"
    if state["intent"] == "save_memo_execute":
        return "save_memo_execute"
    return "general_chat"

# --- LangGraph ê·¸ë˜í”„ ë¹Œë“œ ---
workflow = StateGraph(GraphState)
workflow.add_node("determine_intent", determine_intent)
workflow.add_node("confirm_save_memo", confirm_save_memo_agent)
workflow.add_node("execute_memo_agent", execute_memo_agent)
workflow.add_node("call_general_chat_llm", call_general_chat_llm)

workflow.set_entry_point("determine_intent")

workflow.add_conditional_edges(
    "determine_intent",
    route_intent,
    {
        "faq_check": END,
        "save_memo_execute": "execute_memo_agent",
        "general_chat": "call_general_chat_llm"
    }
)

workflow.add_edge("confirm_save_memo", END)
workflow.add_edge("execute_memo_agent", END)
workflow.add_edge("call_general_chat_llm", END)

memory_saver = MemorySaver()
app_graph = workflow.compile(checkpointer=memory_saver)
print("âœ… LangGraph ì´ˆê¸°í™” ì™„ë£Œ")

# --- FastAPI ---
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    token: str
    conversationHistory: List[dict]
    action: Optional[Literal["EXECUTE_MEMO", "GENERAL_CHAT"]] = None

class StreamRequest(BaseModel):
    query: str
    include_sources: Optional[bool] = True
    token: Optional[str] = None

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """ë©”ì¸ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        decoded_token = verify_firebase_token(request.token)
        uid = decoded_token["uid"]
    except HTTPException as e:
        raise e

    if not db:
        return {
            "success": False,
            "response": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œë¡œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "remainingChats": 0
        }

    # âœ… ë¨¼ì € intent íŒŒì•… (í•œë„ ì°¨ê° ì—†ì´)
    needs_limit_check = False  # ê¸°ë³¸ê°’ ì„¤ì •
    remaining_chats = DAILY_CHAT_LIMIT
    
    try:
        # 1. intent íŒŒì•…ì„ ìœ„í•œ ì„ì‹œ state
        temp_state = GraphState(
            uid=uid,
            message=request.message,
            conversation_history=request.conversationHistory,
            intent="general_chat",
            final_response="",
            search_sources=[],
            has_search_results=False
        )
        
        # 2. actionì— ë”°ë¥¸ intent ì„¤ì •
        if request.action == "EXECUTE_MEMO":
            temp_state["intent"] = "save_memo_execute"
            needs_limit_check = False
        elif request.action == "GENERAL_CHAT":
            temp_state["intent"] = "general_chat"
            needs_limit_check = True
        else:
            # ì¼ë°˜ ì›Œí¬í”Œë¡œìš°: intent íŒŒì•…
            intent_result = determine_intent(temp_state)
            needs_limit_check = intent_result["intent"] == "general_chat"
        
        # 3. í•œë„ ì²´í¬ (ì¼ë°˜ ëŒ€í™”/ê²€ìƒ‰ë§Œ)
        if needs_limit_check:
            print(f"[í•œë„] ğŸ¦ ì¼ë°˜ ëŒ€í™”/ê²€ìƒ‰ - í•œë„ ì²´í¬ ì‹¤í–‰")
            try:
                limit_status = await check_and_update_chat_limit(uid)
                remaining_chats = limit_status["remainingChats"]

                if not limit_status["canChat"]:
                    return {
                        "success": False,
                        "response": "ì¼ì¼ ëŒ€í™” í•œë„(200íšŒ)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.",
                        "remainingChats": 0
                    }
            except Exception as e:
                print(f"âŒ í•œë„ ì²´í¬ ì˜¤ë¥˜: {e}")
        else:
            print(f"[í•œë„] ğŸ†“ ë¬´ë£Œ ê¸°ëŠ¥ (FAQ/ë©”ëª¨) - í•œë„ ì²´í¬ ìƒëµ")

        # 4. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_message = {
            "role": "user",
            "content": request.message,
            "timestamp": datetime.now(timezone.utc)
        }
        save_chat_to_firestore(uid, user_message, db)
        
        # 5. ì‹¤ì œ ì²˜ë¦¬ ìˆ˜í–‰
        graph_input = GraphState(
            uid=uid,
            message=request.message,
            conversation_history=request.conversationHistory,
            intent="general_chat",
            final_response="",
            search_sources=[],
            has_search_results=False
        )
        
        config = {"configurable": {"thread_id": uid}}
        
        # âœ… actionì— ë”°ë¼ ë‹¤ë¥¸ ë…¸ë“œ ì‹¤í–‰
        if request.action == "EXECUTE_MEMO":
            # execute_memo_agent ë…¸ë“œë§Œ ì‹¤í–‰
            graph_input["intent"] = "save_memo_execute"
            final_state = execute_memo_agent(graph_input, uid)
        elif request.action == "GENERAL_CHAT":
            # general_chat ë…¸ë“œë§Œ ì‹¤í–‰
            final_state = call_general_chat_llm(graph_input)
        else:
            # ì •ìƒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            final_state = app_graph.invoke(graph_input, config=config)
        
        # 6. AI ì‘ë‹µ ì €ì¥
        ai_message = {
            "role": "assistant", 
            "content": final_state["final_response"],
            "timestamp": datetime.now(timezone.utc),
            "hasSearchResults": final_state.get("has_search_results", False),
            "searchSources": final_state.get("search_sources", [])
        }
        save_chat_to_firestore(uid, ai_message, db)
        
        return {
            "success": True,
            "response": final_state["final_response"],
            "remainingChats": remaining_chats,
            "needsConfirmation": False,  # ë” ì´ìƒ í™•ì¸ ë‹¨ê³„ ì—†ìŒ
            "hasSearchResults": final_state.get("has_search_results", False),
            "searchSources": final_state.get("search_sources", [])
        }

    except Exception as e:
        print(f"âŒ LangGraph ì˜¤ë¥˜: {e}")
        
        # ì˜¤ë¥˜ ì‹œ í•œë„ ë³µì› (í•œë„ê°€ ì°¨ê°ëœ ê²½ìš°ì—ë§Œ)
        if needs_limit_check and remaining_chats < DAILY_CHAT_LIMIT:
            try:
                today = date.today().isoformat()
                limit_ref = db.collection('users').document(uid).collection('limits').document(today)
                limit_ref.update({'count': firestore.Increment(-1)})
                remaining_chats += 1
                print(f"[í•œë„] ğŸ”„ ì˜¤ë¥˜ë¡œ ì¸í•œ í•œë„ ë³µì›")
            except Exception as restore_error:
                print(f"âŒ í•œë„ ë³µì› ì‹¤íŒ¨: {restore_error}")

        return {
            "success": False,
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "remainingChats": remaining_chats
        }

@app.get("/")
async def health_check():
    return {
        "status": "ok",
        "message": "Modoo Tree AI Chatbot API",
        "db_connected": db is not None
    }

@app.post("/stream")
async def stream_endpoint(request: StreamRequest):
    """FastAPI SSE ìŠ¤íŠ¸ë¦¬ë° ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸"""
    user_input = request.query.strip()
    
    if not user_input:
        raise HTTPException(status_code=400, detail="query í•„ìˆ˜")
    
    def generate_sse():
        start = time.time()
        
        try:
            # ===== 0ï¸âƒ£ ì¿¼ë¦¬ ì •ì œ ë° refresh íƒœê·¸ ê°ì§€ =====
            import re
            from search_api import clean_query as clean_query_func
            
            cleaned_query = clean_query_func(user_input)
            force_refresh = bool(re.search(r'\[refresh:\d+\]', user_input))
            if force_refresh:
                print(f"ğŸ”„ [FastAPI] ìºì‹œ ë¬´ì‹œ í”Œë˜ê·¸ ê°ì§€: '{user_input}' â†’ '{cleaned_query}'")
            
            # ===== 1ï¸âƒ£ ìºì‹œ í™•ì¸ (ì •ì œëœ ì¿¼ë¦¬ë¡œ, force_refreshê°€ Falseì¼ ë•Œë§Œ) =====
            cached_result = memory_cache.get(cleaned_query) if not force_refresh else None
            if cached_result:
                yield sse_format({
                    "stage": "cache",
                    "status": "hit",
                    "message": "ğŸ’¾ ìºì‹œëœ ê²°ê³¼ ë°˜í™˜ ì¤‘..."
                })
                
                # ìºì‹œëœ ìš”ì•½ì„ ìŠ¤íŠ¸ë¦¬ë° í˜•íƒœë¡œ ë°˜í™˜
                summary = cached_result.get("summary", "")
                if summary:
                    # ë¶€ë“œëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
                    chunks = [summary[i:i+20] for i in range(0, len(summary), 20)]
                    for chunk in chunks:
                        yield sse_format({
                            "stage": "synthesis",
                            "status": "streaming",
                            "partial_answer": chunk
                        })
                        time.sleep(0.02)  # ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„
                
                yield sse_format({
                    "stage": "complete",
                    "status": "success",
                    "summary": summary,
                    "sources": cached_result.get("sources", []),
                    "elapsed": time.time() - start,
                    "from_cache": True
                })
                return
            
            # ===== 1ï¸âƒ£ ì¿¼ë¦¬ ë¶„ë¥˜ =====
            yield sse_format({
                "stage": "classify",
                "status": "started",
                "message": "ğŸ” ê²€ìƒ‰ ì¤€ë¹„ ì¤‘..."
            })
            
            from search_api import classify_query, SearchCategory, perform_search
            category, clean_query = classify_query(user_input)
            
            yield sse_format({
                "stage": "classify",
                "status": "finished",
                "category": category.value,
                "message": f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category.value}"
            })

            # ===== 2ï¸âƒ£ CHAT vs SEARCH ë¶„ê¸° =====
            if category == SearchCategory.CHAT:
                yield sse_format({
                    "stage": "chat",
                    "status": "started",
                    "message": "ğŸ’¬ ì¼ë°˜ ëŒ€í™” ëª¨ë“œ"
                })
                
                # Gemini ëŒ€í™”
                model = genai.GenerativeModel(
                    model_name='gemini-2.0-flash-lite',
                    system_instruction=SYSTEM_INSTRUCTION_PERSONA
                )
                
                response = model.generate_content(user_input)
                final_answer = response.text
                
                yield sse_format({
                    "stage": "complete",
                    "status": "finished",
                    "category": category.value,
                    "duration_sec": round(time.time() - start, 2),
                    "answer_summary": final_answer,
                    "sources": [],
                    "message": f"âœ… ì¼ë°˜ ëŒ€í™” ì™„ë£Œ"
                })
                
                # ìºì‹œì— ì €ì¥ (ëŒ€í™”ëŠ” ì§§ì€ TTL)
                cache_data = {
                    "summary": final_answer,
                    "sources": [],
                    "category": category.value
                }
                memory_cache.set(cleaned_query, cache_data)
                return
                
            else:
                # ===== ê²€ìƒ‰ ëª¨ë“œ =====
                yield sse_format({
                    "stage": "search",
                    "status": "started", 
                    "message": f"ğŸ” {category.value} ê²€ìƒ‰ ì¤‘...",
                    "progress": 10
                })
                
                naver_id = os.environ.get("NAVER_CLIENT_ID")
                naver_secret = os.environ.get("NAVER_CLIENT_SECRET")
                serper_key = os.environ.get("SERPER_KEY")
                
                search_result = perform_search(
                    user_input, 
                    genai,
                    naver_id=naver_id,
                    naver_secret=naver_secret,
                    serper_key=serper_key
                )
                
                if search_result.get("success"):
                    yield sse_format({
                        "stage": "complete",
                        "status": "finished",
                        "category": category.value,
                        "duration_sec": round(time.time() - start, 2),
                        "answer_summary": search_result.get("summary", ""),
                        "sources": search_result.get("sources", []),
                        "message": f"âœ… ê²€ìƒ‰ ì™„ë£Œ"
                    })
                    
                    # ìºì‹œì— ì €ì¥
                    memory_cache.set(cleaned_query, search_result)
                else:
                    # ğŸ”¥ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ì—ëŸ¬ ë©”ì‹œì§€ë§Œ (Gemini ì‚¬ìš© ì•ˆ í•¨)
                    yield sse_format({
                        "stage": "complete",
                        "status": "finished",
                        "category": "error",
                        "duration_sec": round(time.time() - start, 2),
                        "answer_summary": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê²€ìƒ‰ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                        "sources": [],
                        "message": f"âš ï¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì˜¤ë¥˜"
                    })

        except Exception as e:
            trace = traceback.format_exc()
            print(f"âŒ FastAPI SSE ì—ëŸ¬: {e}\n{trace}")
            yield sse_format({
                "stage": "error",
                "error": str(e),
                "message": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}"
            })

    return StreamingResponse(
        generate_sse(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )

@app.get("/health")
async def health():
    return {"status": "healthy"}

# ===== Flask ì•± (SSE ìŠ¤íŠ¸ë¦¬ë°ìš©) =====
flask_app = Flask(__name__)

# CORS ì„¤ì • (ëª¨ë“  ì¶œì²˜ í—ˆìš©)
CORS(flask_app, 
     resources={r"/*": {"origins": "*"}},
     allow_headers=["Content-Type", "Authorization"],
     methods=["GET", "POST", "OPTIONS"],
     expose_headers=["Content-Type"],
     max_age=3600)

def sse_format(data: dict) -> str:
    """SSE í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

@flask_app.route("/stream", methods=["POST", "OPTIONS"])
def stream_search():
    """SSE ìŠ¤íŠ¸ë¦¬ë° ê²€ìƒ‰"""
    # OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
    if request.method == "OPTIONS":
        print("ğŸ“¨ OPTIONS ìš”ì²­ ìˆ˜ì‹ ")
        response = Response("", status=200)
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
        response.headers["Access-Control-Max-Age"] = "3600"
        return response

    print(f"ğŸ“¨ POST ìš”ì²­ ìˆ˜ì‹ ")
    req = request.get_json(silent=True) or {}
    user_input = req.get("query", "").strip()
    
    if not user_input:
        return Response(
            sse_format({"error": "query í•„ìˆ˜"}),
            mimetype="text/event-stream"
        )

    def generate():
        start = time.time()
        
        try:
            # ===== 0ï¸âƒ£ ì¿¼ë¦¬ ì •ì œ ë° refresh íƒœê·¸ ê°ì§€ =====
            import re
            from search_api import clean_query as clean_query_func
            
            cleaned_query = clean_query_func(user_input)
            force_refresh = bool(re.search(r'\[refresh:\d+\]', user_input))
            if force_refresh:
                print(f"ğŸ”„ [Flask] ìºì‹œ ë¬´ì‹œ í”Œë˜ê·¸ ê°ì§€: '{user_input}' â†’ '{cleaned_query}'")
            
            # ===== 1ï¸âƒ£ ìºì‹œ í™•ì¸ (ì •ì œëœ ì¿¼ë¦¬ë¡œ, force_refreshê°€ Falseì¼ ë•Œë§Œ) =====
            cached_result = memory_cache.get(cleaned_query) if not force_refresh else None
            if cached_result:
                yield sse_format({
                    "stage": "cache",
                    "status": "hit",
                    "message": "ğŸ’¾ ìºì‹œëœ ê²°ê³¼ ë°˜í™˜ ì¤‘..."
                })
                
                # ìºì‹œëœ ìš”ì•½ì„ ìŠ¤íŠ¸ë¦¬ë° í˜•íƒœë¡œ ë°˜í™˜
                summary = cached_result.get("summary", "")
                if summary:
                    # ë¶€ë“œëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
                    chunks = [summary[i:i+20] for i in range(0, len(summary), 20)]
                    for chunk in chunks:
                        yield sse_format({
                            "stage": "synthesis",
                            "status": "streaming",
                            "partial_answer": chunk
                        })
                        time.sleep(0.02)  # ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„
                
                yield sse_format({
                    "stage": "complete",
                    "status": "success",
                    "summary": summary,
                    "sources": cached_result.get("sources", []),
                    "elapsed": time.time() - start,
                    "from_cache": True
                })
                return
            
            # ===== 1ï¸âƒ£ ì¿¼ë¦¬ ë¶„ë¥˜ =====
            yield sse_format({
                "stage": "classify",
                "status": "started",
                "message": "ğŸ” ê²€ìƒ‰ ì¤€ë¹„ ì¤‘..."
            })
            
            from search_api import classify_query, SearchCategory, perform_search
            category, clean_query = classify_query(user_input)
            
            yield sse_format({
                "stage": "classify",
                "status": "finished",
                "category": category.value,
                "message": f"ğŸ“‚ ì¹´í…Œê³ ë¦¬: {category.value}"
            })

            # ===== 2ï¸âƒ£ CHAT vs SEARCH ë¶„ê¸° =====
            if category == SearchCategory.CHAT:
                yield sse_format({
                    "stage": "chat",
                    "status": "started",
                    "message": "ğŸ’¬ ì¼ë°˜ ëŒ€í™” ëª¨ë“œ"
                })
                
                # Gemini ëŒ€í™”
                model = genai.GenerativeModel(
                    model_name='gemini-2.0-flash-lite',
                    system_instruction=SYSTEM_INSTRUCTION_PERSONA
                )
                
                response = model.generate_content(user_input)
                final_answer = response.text
                
                yield sse_format({
                    "stage": "complete",
                    "status": "finished",
                    "category": category.value,
                    "duration_sec": round(time.time() - start, 2),
                    "answer_summary": final_answer,
                    "sources": [],
                    "message": f"âœ… ì¼ë°˜ ëŒ€í™” ì™„ë£Œ"
                })
                
                # ìºì‹œì— ì €ì¥ (ëŒ€í™”ëŠ” ì§§ì€ TTL)
                cache_data = {
                    "summary": final_answer,
                    "sources": [],
                    "category": category.value
                }
                memory_cache.set(cleaned_query, cache_data)
                return
                
            else:
                # ===== ê²€ìƒ‰ ëª¨ë“œ =====
                yield sse_format({
                    "stage": "search",
                    "status": "started", 
                    "message": f"ğŸ” {category.value} ê²€ìƒ‰ ì¤‘...",
                    "progress": 10
                })
                
                naver_id = os.environ.get("NAVER_CLIENT_ID")
                naver_secret = os.environ.get("NAVER_CLIENT_SECRET")
                serper_key = os.environ.get("SERPER_KEY")
                
                search_result = perform_search(
                    user_input, 
                    genai,
                    naver_id=naver_id,
                    naver_secret=naver_secret,
                    serper_key=serper_key
                )
                
                if search_result.get("success"):
                    yield sse_format({
                        "stage": "complete",
                        "status": "finished",
                        "category": category.value,
                        "duration_sec": round(time.time() - start, 2),
                        "answer_summary": search_result.get("summary", ""),
                        "sources": search_result.get("sources", []),
                        "message": f"âœ… ê²€ìƒ‰ ì™„ë£Œ"
                    })
                    
                    # ìºì‹œì— ì €ì¥
                    memory_cache.set(cleaned_query, search_result)
                else:
                    yield sse_format({
                        "stage": "error",
                        "error": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                    })

        except Exception as e:
            trace = traceback.format_exc()
            print(f"âŒ SSE ì—ëŸ¬: {e}\n{trace}")
            yield sse_format({
                "stage": "error",
                "error": str(e),
                "message": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}"
            })

    return Response(
        generate(),
        mimetype="text/event-stream",
        headers={
            "Access-Control-Allow-Origin": "*",
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        }
    )

@flask_app.route("/health", methods=["GET"])
def flask_health_check():
    """Flask ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    cache_stats = memory_cache.get_stats()
    return jsonify({
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "gemini": genai is not None,
            "naver": os.environ.get("NAVER_CLIENT_ID") is not None,
            "serper": os.environ.get("SERPER_KEY") is not None,
        },
        "cache": cache_stats
    }), 200

@flask_app.route("/cache/clear", methods=["POST"])
def clear_cache():
    """ìºì‹œ ìˆ˜ë™ ì‚­ì œ (ê´€ë¦¬ììš©)"""
    memory_cache.clear()
    return jsonify({"message": "ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}), 200

@flask_app.route("/cache/stats", methods=["GET"])
def cache_stats():
    """ìºì‹œ í†µê³„"""
    return jsonify(memory_cache.get_stats()), 200

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    
    # ê°œë°œ í™˜ê²½ì—ì„œëŠ” Flask ì‹¤í–‰ (SSE ì§€ì›)
    if os.environ.get("FLASK_ENV") == "development":
        print("ğŸš€ Flask ê°œë°œ ì„œë²„ë¡œ ì‹¤í–‰ (SSE ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)...")
        flask_app.run(host="0.0.0.0", port=port, debug=False, threaded=True)
    else:
        # í”„ë¡œë•ì…˜ì—ì„œëŠ” FastAPI ì‹¤í–‰ (ê¸°ë³¸ ì±„íŒ…)
        print("ğŸš€ FastAPI í”„ë¡œë•ì…˜ ì„œë²„ë¡œ ì‹¤í–‰...")
        uvicorn.run(app, host="0.0.0.0", port=port)
